"""
Export SAM2 encoder to ONNX and compile for Hailo-10H.

This script prepares SAM2-Tiny for deployment on Hailo AI HAT+2.

Steps:
1. Export SAM2 encoder to ONNX
2. Compile ONNX to Hailo HEF format (on Hailo Dataflow Compiler)

Requirements on Windows (export ONNX):
    pip install torch onnx onnxruntime

Requirements on Hailo Dataflow Compiler (compile HEF):
    Run on Hailo-provided Docker or Linux machine with Hailo SDK

Usage:
    # Step 1: Export ONNX (on Windows)
    python export_sam2_hailo.py --export-onnx

    # Step 2: Compile HEF (on Hailo SDK machine)
    hailo parser onnx sam2_encoder.onnx --hw-arch hailo10h --har-path sam2_encoder.har
    hailo compiler sam2_encoder.har --hw-arch hailo10h -o sam2_encoder_hailo10h.hef
"""

import os
import sys
import argparse
from pathlib import Path

import torch
import torch.nn as nn
import numpy as np

try:
    from onnxsim import simplify as onnx_simplify
except ImportError:
    onnx_simplify = None

try:
    import onnx_graphsurgeon as gs
except ImportError:
    gs = None

# ==============================================================================
# HAILO COMPATIBILITY MONKEY-PATCHES
# ==============================================================================
# SAM2's windowing logic uses conditional padding which creates 'If' nodes
# that the Hailo parser (v5.2.0) cannot handle. Since we use a static 896x896
# input, we can replace these with static operations.

import sam2.modeling.backbones.utils as sam2_utils

def patched_pad_at_period(x, period):
    """
    Hailo-friendly padding: Assumes input is already a multiple of period.
    This eliminates the 'If' nodes generated by the original implementation.
    """
    # Simply return the input - at 896x896, SAM2's stages are all multiples of windows.
    return x, 0, 0

def patched_window_partition(x, window_size):
    """
    Hailo-friendly window partition: Uses explicit view/permute without 
    conditional branching.
    """
    B, H, W, C = x.shape
    x = x.view(-1, H // window_size, window_size, W // window_size, window_size, C)
    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)
    # Return windows and the original H, W as pad_hw (expected by SAM2 forward)
    return windows, (H, W)

# Apply the patches
sam2_utils.pad_at_period = patched_pad_at_period
sam2_utils.window_partition = patched_window_partition
print("\n[HAILO] Applied monkey-patches to SAM2 utilities to remove dynamic nodes.")
# ==============================================================================


def export_sam2_encoder_onnx(
    checkpoint_path: str = "checkpoints/sam2_hiera_tiny.pt",
    output_path: str = "edge/sam2_encoder.onnx",
    image_size: int = 896
):
    """
    Export SAM2 Hiera-Tiny encoder to ONNX.

    The encoder is the heavy part - runs on Hailo-10H (40 TOPS).
    The mask decoder is lightweight - runs on CPU.
    """
    print("="*60)
    print("Exporting SAM2 Encoder to ONNX")
    print("="*60)

    # Create output directory
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    try:
        from sam2.build_sam import build_sam2
        
        print(f"Loading SAM2 from {checkpoint_path}...")
        
        # The config name should be the basename without .yaml
        # And build_sam2 expects it to be in the sam2_configs path
        # We'll use the absolute path to be safe
        config_path = os.path.abspath("sam2_hiera_t.yaml")
        if not os.path.exists(config_path):
            print(f"ERROR: Config file not found at {config_path}")
            sys.exit(1)
            
        model = build_sam2(
            config_path,
            checkpoint_path,
            device="cpu"
        )
        model.eval()

        # Extract just the image encoder
        encoder = model.image_encoder

        print(f"Encoder parameters: {sum(p.numel() for p in encoder.parameters()):,}")

    except ImportError:
        print("SAM2 not installed. Creating a mock encoder for testing.")

        # Mock encoder for testing the export pipeline
        class MockHieraEncoder(nn.Module):
            def __init__(self):
                super().__init__()
                self.conv1 = nn.Conv2d(3, 64, 7, stride=4, padding=3)
                self.conv2 = nn.Conv2d(64, 128, 3, stride=2, padding=1)
                self.conv3 = nn.Conv2d(128, 256, 3, stride=2, padding=1)
                self.avg_pool = nn.AdaptiveAvgPool2d((64, 64))

            def forward(self, x):
                x = torch.relu(self.conv1(x))
                x = torch.relu(self.conv2(x))
                x = torch.relu(self.conv3(x))
                x = self.avg_pool(x)
                return x

        encoder = MockHieraEncoder()
        print("Using mock encoder (SAM2 not available)")

    # Create dummy input
    dummy_input = torch.randn(1, 3, image_size, image_size)

    print(f"Input shape: {dummy_input.shape}")

    # Test forward pass
    with torch.no_grad():
        output = encoder(dummy_input)
    
    if isinstance(output, torch.Tensor):
        print(f"Output shape: {output.shape}")
    elif isinstance(output, (list, tuple)):
        print(f"Output is list/tuple with {len(output)} elements")
        for i, out in enumerate(output):
            if isinstance(out, torch.Tensor):
                print(f"  [{i}] shape: {out.shape}")
    elif isinstance(output, dict):
        print(f"Output is dict with keys: {list(output.keys())}")
        for k, v in output.items():
            if isinstance(v, torch.Tensor):
                print(f"  {k} shape: {v.shape}")
            elif isinstance(v, list):
                print(f"  {k} is list of length {len(v)}")

    # Define the wrapper class
    class SAM2EncoderWrapper(nn.Module):
        def __init__(self, encoder):
            super().__init__()
            self.encoder = encoder
            
        def forward(self, x):
            # Wrapper for DFC-friendly export
            # We explicitly permute to NHWC if possible, but DFC usually handles it.
            # More importantly, we ensure the output is a single tensor.
            outputs = self.encoder(x)
            return outputs["vision_features"]

    # Wrap the encoder
    wrapped_encoder = SAM2EncoderWrapper(encoder)
    print("Wrapped encoder for clean ONNX export (returning 'vision_features')")

    # Export to ONNX
    print(f"\nExporting to {output_path}...")

    # Export the WRAPPED encoder
    torch.onnx.export(
        wrapped_encoder,
        dummy_input,
        output_path,
        export_params=True,
        opset_version=16,  # Opset 16 supports 'tile' and is well-supported by Hailo 5.x
        do_constant_folding=True,
        dynamo=False,
        input_names=["input"],
        output_names=["output"],
        # Removed dynamic_axes for better Hailo compatibility (batch 1 static)
    )

    print(f"ONNX model saved to: {output_path}")
    print(f"File size: {os.path.getsize(output_path) / 1024 / 1024:.1f} MB")

    # Step 1: Use GraphSurgeon for aggressive constant folding
    if gs:
        print("\nApplying ONNX GraphSurgeon constant folding...")
        try:
            import onnx
            model_gs = onnx.load(output_path)
            graph = gs.import_onnx(model_gs)
            graph.fold_constants().cleanup()
            onnx.save(gs.export_onnx(graph), output_path)
            print("  GraphSurgeon: SUCCESS")
        except Exception as e:
            print(f"  GraphSurgeon error: {e}")
    else:
        print("\nonnx-graphsurgeon not installed. Skipping folding.")

    # Step 2: Simplify ONNX model
    if onnx_simplify:
        print("\nSimplifying ONNX model with onnx-simplifier...")
        try:
            import onnx
            model_onnx = onnx.load(output_path)
            # Use newest onnxsim arguments
            model_simp, check = onnx_simplify(
                model_onnx,
                skipped_optimizers=["eliminate_nop_pad"],
                overwrite_input_shapes={"input": [1, 3, image_size, image_size]},
                include_subgraph=True # Crucial for 'If' nodes
            )
            if check:
                onnx.save(model_simp, output_path)
                print("  Simplification: SUCCESS")
            else:
                print("  Simplification: FAILED (post-check failed)")
        except Exception as e:
            print(f"  Simplification error: {e}")
    else:
        print("\nonnx-simplifier not installed. Run: pip install onnxsim")


    # Verify ONNX model
    try:
        import onnx
        import onnxruntime as ort

        print("\nVerifying ONNX model...")
        onnx_model = onnx.load(output_path)
        onnx.checker.check_model(onnx_model)
        print("  ONNX model check: PASSED")

        # Test inference with ONNX Runtime
        session = ort.InferenceSession(output_path)
        ort_inputs = {"input": dummy_input.numpy()}
        ort_outputs = session.run(None, ort_inputs)
        print(f"  ONNX Runtime inference: PASSED")
        print(f"  Output shape: {ort_outputs[0].shape}")

    except ImportError:
        print("onnx/onnxruntime not installed. Skipping verification.")

    print("\n" + "="*60)
    print("NEXT STEPS for Hailo Compilation:")
    print("="*60)
    print("""
1. Copy the ONNX file to your Hailo compilation environment:
   scp edge/models/sam2_encoder.onnx user@hailo-machine:~/

2. On the Hailo machine, run:
   hailo parser onnx sam2_encoder.onnx --hw-arch hailo10h --har-path sam2_encoder.har
   hailo compiler sam2_encoder.har \\
       --hw-arch hailo10h \\
       --output-dir ./hailo_output \\
       -o sam2_encoder_hailo10h.hef

3. Copy the HEF file back:
   scp user@hailo-machine:~/hailo_output/sam2_encoder_hailo10h.hef edge/models/

4. Or use Hailo Model Zoo precompiled models if available.
""")

    return output_path


def create_hailo_calibration_data(
    output_dir: str = "edge/models/calibration",
    num_samples: int = 100,
    image_size: int = 1024
):
    """
    Create calibration data for Hailo quantization.

    Hailo compiler needs representative data for INT8 quantization.
    """
    print("Creating calibration data for Hailo quantization...")
    os.makedirs(output_dir, exist_ok=True)

    # Try to use real medical images
    try:
        from PIL import Image
        import glob

        medical_images = glob.glob("medical_data/**/*.png", recursive=True)
        medical_images += glob.glob("medical_data/**/*.jpg", recursive=True)

        if medical_images:
            print(f"Found {len(medical_images)} medical images")
            num_samples = min(num_samples, len(medical_images))

            for i, img_path in enumerate(medical_images[:num_samples]):
                img = Image.open(img_path).convert("RGB")
                img = img.resize((image_size, image_size))
                img_array = np.array(img, dtype=np.float32) / 255.0
                img_array = np.transpose(img_array, (2, 0, 1))  # HWC -> CHW

                np.save(os.path.join(output_dir, f"sample_{i:04d}.npy"), img_array)

            print(f"Saved {num_samples} calibration samples")
            return
    except Exception as e:
        print(f"Could not load medical images: {e}")

    # Fall back to random data
    print("Using random calibration data (not optimal)")
    for i in range(num_samples):
        sample = np.random.randn(3, image_size, image_size).astype(np.float32)
        sample = (sample - sample.min()) / (sample.max() - sample.min())
        np.save(os.path.join(output_dir, f"sample_{i:04d}.npy"), sample)

    print(f"Saved {num_samples} random calibration samples")


def main():
    parser = argparse.ArgumentParser(
        description="Export SAM2 for Hailo-10H deployment"
    )
    parser.add_argument("--export-onnx", action="store_true",
                        help="Export SAM2 encoder to ONNX")
    parser.add_argument("--create-calibration", action="store_true",
                        help="Create calibration data for Hailo quantization")
    parser.add_argument("--checkpoint", default="checkpoints/sam2_hiera_tiny.pt",
                        help="SAM2 checkpoint path")
    parser.add_argument("--output", default="edge/sam2_encoder.onnx",
                        help="ONNX output path")
    parser.add_argument("--image-size", type=int, default=896,
                        help="Input image size")

    args = parser.parse_args()

    if args.export_onnx:
        export_sam2_encoder_onnx(
            checkpoint_path=args.checkpoint,
            output_path=args.output,
            image_size=args.image_size
        )

    if args.create_calibration:
        create_hailo_calibration_data(
            image_size=args.image_size
        )

    if not args.export_onnx and not args.create_calibration:
        parser.print_help()


if __name__ == "__main__":
    main()
